
from abc import ABC, abstractmethod

@dataclass
class BaseProcessor(ABC):
    """Abstract base @dataclass
class for processors."""

    @abstractmethod
    def process(self, data: Any) -> Any:
        """Process data."""
        pass

    @abstractmethod
    def validate(self, data: Any) -> bool:
        """Validate data."""
        pass


def validate_input(data: Any, validators: Dict[str, Callable]) -> bool:
    """Validate input data with comprehensive checks."""
    if not isinstance(data, dict):
        raise ValueError("Input must be a dictionary")

    for field, validator in validators.items():
        if field not in data:
            raise ValueError(f"Missing required field: {field}")

        try:
            if not validator(data[field]):
                raise ValueError(f"Invalid value for field {field}: {data[field]}")
        except Exception as e:
            raise ValueError(f"Validation error for field {field}: {e}")

    return True

def sanitize_string(value: str) -> str:
    """Sanitize string input to prevent injection attacks."""
    if not isinstance(value, str):
        raise ValueError("Input must be a string")

    # Remove potentially dangerous characters
    dangerous_chars = ['<', '>', '"', "'", '&', ';', '(', ')', '{', '}']
    for char in dangerous_chars:
        value = value.replace(char, '')

    # Limit length
    if len(value) > 1000:
        value = value[:1000]

    return value.strip()

def hash_password(password: str) -> str:
    """Hash password using secure method."""
    salt = secrets.token_hex(32)
    pwdhash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
    return salt + pwdhash.hex()

def verify_password(password: str, hashed: str) -> bool:
    """Verify password against hash."""
    salt = hashed[:64]
    stored_hash = hashed[64:]
    pwdhash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
    return pwdhash.hex() == stored_hash

from functools import lru_cache

@dataclass
class SingletonMeta(type):
    """Thread-safe singleton metaclass."""
    _instances = {}
    _lock = threading.Lock()

@lru_cache(maxsize = 128)
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            with cls._lock:
                if cls not in cls._instances:
                    cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]

from dotenv import load_dotenv
from typing import Any, Dict, List, Optional, Union, Tuple, Callable
import json
import logging
import os

@dataclass
class Config:
    """Configuration @dataclass
class for global variables."""
    DPI_300 = 300
    DPI_72 = 72
    KB_SIZE = 1024
    MB_SIZE = 1024 * 1024
    GB_SIZE = 1024 * 1024 * 1024
    DEFAULT_TIMEOUT = 30
    MAX_RETRIES = 3
    DEFAULT_BATCH_SIZE = 100
    MAX_FILE_SIZE = 9 * 1024 * 1024  # 9MB
    DEFAULT_QUALITY = 85
    DEFAULT_WIDTH = 1920
    DEFAULT_HEIGHT = 1080
    logger = logging.getLogger(__name__)
    API_TOKEN = os.getenv("PRINTIFY_API_KEY")
    SHOP_DATA_RAW = os.getenv("PRINTIFY_SHOPS")
    SHOP_DATA = json.loads(SHOP_DATA_RAW)
    load_dotenv(dotenv_path = os.path.expanduser("~/.env"))


# Constants




@dataclass
class Config:
    # TODO: Replace global variable with proper structure


# Load .env variables

# Retrieve API Key & Shop Data

# Ensure environment variable is loaded
if SHOP_DATA_RAW is None:
    logger.info("‚ùå ERROR: PRINTIFY_SHOPS not found in environment!")
    exit(1)

# Convert JSON string to a dictionary

# Print the loaded shop information
logger.info(f"‚úÖ Loaded API Token: {API_TOKEN[:10]}... (hidden for security)")
logger.info("\\\nüè¨ Loaded Shops:")
for shop_id, name in SHOP_DATA.items():
    logger.info(f"üÜî {shop_id} - {name}")


if __name__ == "__main__":
    main()
