{
    "sourceFile": "organizer.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1757087692328,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1757089390367,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,13 +19,13 @@\n # Load environment variables\n load_dotenv(\"/Users/steven/.env\")\n \n # Initialize OpenAI\n+openai = None\n try:\n     openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n except Exception as e:\n-    logging.error(f\"OpenAI initialization failed: {str(e)}\")\n-    openai = None\n+    logging.error(\"OpenAI initialization failed: %s\", e)\n \n # Configuration\n CONFIG_DIR = Path(\"/Users/steven/.config/file_organizer\")\n CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n@@ -51,11 +51,8 @@\n     re.compile(r\"^\\..*\"),  # Hidden files/dirs (starting with dot)\n     re.compile(r\".*/(?:venv|env|\\.venv|\\.env)/.*\"),  # Python virtual environments\n     re.compile(r\".*/(?:my_global_venv|\\.my_global_venv)/.*\"),  # Global venv\n     re.compile(r\".*/(?:simplegallery|avatararts|github)/.*\"),  # Specific excluded directories\n-    re.compile(\n-        r\".*/(?:simplegallery|avatararts|github)/.*\"\n-    ),  # Specific excluded directories\n     re.compile(r\".*/Documents/gitHub/.*\"),  # GitHub folder inside Documents\n     re.compile(r\".*/node/.*\"),  # Node-related directories\n     re.compile(r\".*/Movies/(?:CapCut|movavi)/.*\"),  # Video editing software\n     re.compile(r\".*/miniconda3/.*\"),  # Conda environments\n"
                },
                {
                    "date": 1757089402948,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,9 +60,8 @@\n     re.compile(r\".*/\\.(?:config|spicetify|gem|zprofile)/.*\"),  # Hidden config folders\n     re.compile(r\".*/\\..*\"),  # General hidden directories\n ]\n \n-\n def prompt_for_directory() -> Path:\n     \"\"\"Prompt the user to input a directory path.\"\"\"\n     while True:\n         directory = input(\"Enter the directory to scan (or 'q' to quit): \").strip()\n"
                },
                {
                    "date": 1757089408401,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,27 +71,24 @@\n \n         path = Path(directory)\n         if path.is_dir():\n             return path\n-        logging.error(f\"Invalid directory: {directory}. Please try again.\")\n+        logging.error(\"Invalid directory: %s. Please try again.\", directory)\n \n-\n @contextmanager\n def safe_file_access(filepath: Path):\n     \"\"\"Context manager for safe file handling with error logging.\"\"\"\n     try:\n         with open(filepath, \"r\", encoding=\"utf-8\") as f:\n             yield f\n     except Exception as e:\n-        logging.error(f\"Failed to access {filepath}: {str(e)}\")\n+        logging.error(\"Failed to access %s: %s\", filepath, e)\n         yield None\n \n-\n def should_exclude(path: Path) -> bool:\n     \"\"\"Check if a path matches any exclusion pattern.\"\"\"\n     return any(pattern.search(str(path)) for pattern in EXCLUDED_PATTERNS)\n \n-\n class FileProcessor:\n     \"\"\"Base class for file processing operations.\"\"\"\n \n     @staticmethod\n"
                },
                {
                    "date": 1757089416668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,9 +95,9 @@\n     def get_creation_date(filepath: Path) -> str:\n         try:\n             return datetime.fromtimestamp(filepath.stat().st_ctime).strftime(\"%m-%d-%y\")\n         except Exception as e:\n-            logging.error(f\"Creation date error for {filepath}: {str(e)}\")\n+            logging.error(\"Creation date error for %s: %s\", filepath, e)\n             return \"Unknown\"\n \n     @staticmethod\n     def format_file_size(size_in_bytes: int) -> str:\n@@ -125,12 +125,11 @@\n                 if hours\n                 else f\"{int(minutes):02}:{int(seconds):02}\"\n             )\n         except Exception as e:\n-            logging.error(f\"Duration formatting error: {str(e)}\")\n+            logging.error(\"Duration formatting error: %s\", e)\n             return \"Unknown\"\n \n-\n class MediaProcessor(FileProcessor):\n     \"\"\"Handles media file processing with metadata extraction.\"\"\"\n \n     @classmethod\n"
                },
                {
                    "date": 1757089423622,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,9 +143,9 @@\n                 \"size\": cls.format_file_size(filepath.stat().st_size),\n                 \"created\": cls.get_creation_date(filepath),\n             }\n         except Exception as e:\n-            logging.error(f\"Audio processing failed for {filepath}: {str(e)}\")\n+            logging.error(\"Audio processing failed for %s: %s\", filepath, e)\n             return None\n \n     @classmethod\n     def process_image(cls, filepath: Path) -> Optional[Dict]:\n@@ -159,9 +159,9 @@\n                     \"size\": cls.format_file_size(filepath.stat().st_size),\n                     \"created\": cls.get_creation_date(filepath),\n                 }\n         except Exception as e:\n-            logging.error(f\"Image processing failed for {filepath}: {str(e)}\")\n+            logging.error(\"Image processing failed for %s: %s\", filepath, e)\n             return None\n \n     @classmethod\n     def process_video(cls, filepath: Path) -> Optional[Dict]:\n"
                },
                {
                    "date": 1757089434074,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -182,12 +182,11 @@\n                 \"size\": cls.format_file_size(filepath.stat().st_size),\n                 \"created\": cls.get_creation_date(filepath),\n             }\n         except Exception as e:\n-            logging.error(f\"Video processing failed for {filepath}: {str(e)}\")\n+            logging.error(\"Video processing failed for %s: %s\", filepath, e)\n             return None\n \n-\n class ScriptAnalyzer:\n     \"\"\"Handles script analysis using OpenAI.\"\"\"\n \n     @retry(\n@@ -212,9 +211,9 @@\n                 self._parse_response(choice.message.content, script[\"path\"])\n                 for choice, script in zip(response.choices, scripts)\n             ]\n         except Exception as e:\n-            logging.error(f\"AI analysis failed: {str(e)}\")\n+            logging.error(\"AI analysis failed: %s\", e)\n             return [{\"error\": str(e)}] * len(scripts)\n \n     def _parse_response(self, response: str, filepath: Path) -> Dict:\n         # Add your custom response parsing logic here\n"
                },
                {
                    "date": 1757089439692,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -224,9 +224,8 @@\n             \"title\": \"Untitled\",\n             \"analysis\": response,\n         }\n \n-\n def process_directory(\n     root_dir: Path, processor: MediaProcessor, file_type: str\n ) -> List[Dict]:\n     \"\"\"Process all files in directory with appropriate handlers.\"\"\"\n@@ -247,9 +246,8 @@\n                 if result:\n                     results.append(result)\n     return results\n \n-\n def write_results(results: List[Dict], output_path: Path):\n     \"\"\"Write processed results to CSV.\"\"\"\n     if not results:\n         logging.warning(\"No results to write\")\n"
                },
                {
                    "date": 1757089445584,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -258,13 +258,12 @@\n         with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n             writer = csv.DictWriter(f, fieldnames=fieldnames)\n             writer.writeheader()\n             writer.writerows(results)\n-        logging.info(f\"Successfully wrote {len(results)} records to {output_path}\")\n+        logging.info(\"Successfully wrote %d records to %s\", len(results), output_path)\n     except Exception as e:\n-        logging.error(f\"Failed to write CSV: {str(e)}\")\n+        logging.error(\"Failed to write CSV: %s\", e)\n \n-\n def main():\n     # Initialize processors\n     media_processor = MediaProcessor()\n     script_analyzer = ScriptAnalyzer()\n@@ -279,9 +278,8 @@\n             output_path = CONFIG_DIR / f\"{file_type}_analysis.csv\"\n             write_results(results, output_path)\n \n     # Process scripts\n-    script_results = []\n     scripts_to_analyze = []\n     for script_path in directory.rglob(\"*.py\"):\n         if should_exclude(script_path):\n             continue\n"
                }
            ],
            "date": 1757087692328,
            "name": "Commit-0",
            "content": "import csv\nimport logging\nimport os\nimport re\nfrom contextlib import contextmanager\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\n\nfrom dotenv import load_dotenv\nfrom mutagen import File  # For handling .webm files\nfrom mutagen.easyid3 import EasyID3\nfrom mutagen.mp3 import MP3\nfrom mutagen.mp4 import MP4\nfrom openai import OpenAI\nfrom PIL import Image\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\n# Load environment variables\nload_dotenv(\"/Users/steven/.env\")\n\n# Initialize OpenAI\ntry:\n    openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\nexcept Exception as e:\n    logging.error(f\"OpenAI initialization failed: {str(e)}\")\n    openai = None\n\n# Configuration\nCONFIG_DIR = Path(\"/Users/steven/.config/file_organizer\")\nCONFIG_DIR.mkdir(parents=True, exist_ok=True)\n\n# Logging setup\nLOG_FILE = CONFIG_DIR / \"file_organizer.log\"\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler()],\n)\n\n# File type mappings\nFILE_TYPES = {\n    \"audio\": {\".mp3\", \".wav\", \".flac\", \".aac\", \".m4a\"},\n    \"image\": {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\"},\n    \"video\": {\".mp4\", \".mkv\", \".mov\", \".avi\", \".wmv\", \".webm\"},\n    \"scripts\": {\".py\"},\n}\n\n# Regex patterns for exclusions\nEXCLUDED_PATTERNS = [\n    re.compile(r\"^\\..*\"),  # Hidden files/dirs (starting with dot)\n    re.compile(r\".*/(?:venv|env|\\.venv|\\.env)/.*\"),  # Python virtual environments\n    re.compile(r\".*/(?:my_global_venv|\\.my_global_venv)/.*\"),  # Global venv\n    re.compile(r\".*/(?:simplegallery|avatararts|github)/.*\"),  # Specific excluded directories\n    re.compile(\n        r\".*/(?:simplegallery|avatararts|github)/.*\"\n    ),  # Specific excluded directories\n    re.compile(r\".*/Documents/gitHub/.*\"),  # GitHub folder inside Documents\n    re.compile(r\".*/node/.*\"),  # Node-related directories\n    re.compile(r\".*/Movies/(?:CapCut|movavi)/.*\"),  # Video editing software\n    re.compile(r\".*/miniconda3/.*\"),  # Conda environments\n    re.compile(r\".*/Library/.*\"),  # macOS Library folder\n    re.compile(r\".*/\\.(?:config|spicetify|gem|zprofile)/.*\"),  # Hidden config folders\n    re.compile(r\".*/\\..*\"),  # General hidden directories\n]\n\n\ndef prompt_for_directory() -> Path:\n    \"\"\"Prompt the user to input a directory path.\"\"\"\n    while True:\n        directory = input(\"Enter the directory to scan (or 'q' to quit): \").strip()\n        if directory.lower() == \"q\":\n            logging.info(\"Exiting as requested by user.\")\n            exit(0)\n\n        path = Path(directory)\n        if path.is_dir():\n            return path\n        logging.error(f\"Invalid directory: {directory}. Please try again.\")\n\n\n@contextmanager\ndef safe_file_access(filepath: Path):\n    \"\"\"Context manager for safe file handling with error logging.\"\"\"\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            yield f\n    except Exception as e:\n        logging.error(f\"Failed to access {filepath}: {str(e)}\")\n        yield None\n\n\ndef should_exclude(path: Path) -> bool:\n    \"\"\"Check if a path matches any exclusion pattern.\"\"\"\n    return any(pattern.search(str(path)) for pattern in EXCLUDED_PATTERNS)\n\n\nclass FileProcessor:\n    \"\"\"Base class for file processing operations.\"\"\"\n\n    @staticmethod\n    def get_creation_date(filepath: Path) -> str:\n        try:\n            return datetime.fromtimestamp(filepath.stat().st_ctime).strftime(\"%m-%d-%y\")\n        except Exception as e:\n            logging.error(f\"Creation date error for {filepath}: {str(e)}\")\n            return \"Unknown\"\n\n    @staticmethod\n    def format_file_size(size_in_bytes: int) -> str:\n        thresholds = [\n            (1 << 40, \"TB\"),\n            (1 << 30, \"GB\"),\n            (1 << 20, \"MB\"),\n            (1 << 10, \"KB\"),\n            (1, \"B\"),\n        ]\n        for factor, suffix in thresholds:\n            if size_in_bytes >= factor:\n                return f\"{size_in_bytes / factor:.2f} {suffix}\"\n        return \"Unknown\"\n\n    @staticmethod\n    def format_duration(seconds: Optional[float]) -> str:\n        if seconds is None:\n            return \"Unknown\"\n        try:\n            hours, remainder = divmod(seconds, 3600)\n            minutes, seconds = divmod(remainder, 60)\n            return (\n                f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n                if hours\n                else f\"{int(minutes):02}:{int(seconds):02}\"\n            )\n        except Exception as e:\n            logging.error(f\"Duration formatting error: {str(e)}\")\n            return \"Unknown\"\n\n\nclass MediaProcessor(FileProcessor):\n    \"\"\"Handles media file processing with metadata extraction.\"\"\"\n\n    @classmethod\n    def process_audio(cls, filepath: Path) -> Optional[Dict]:\n        try:\n            audio = MP3(filepath, ID3=EasyID3)\n            return {\n                \"type\": \"audio\",\n                \"path\": str(filepath),\n                \"duration\": cls.format_duration(audio.info.length),\n                \"size\": cls.format_file_size(filepath.stat().st_size),\n                \"created\": cls.get_creation_date(filepath),\n            }\n        except Exception as e:\n            logging.error(f\"Audio processing failed for {filepath}: {str(e)}\")\n            return None\n\n    @classmethod\n    def process_image(cls, filepath: Path) -> Optional[Dict]:\n        try:\n            with Image.open(filepath) as img:\n                return {\n                    \"type\": \"image\",\n                    \"path\": str(filepath),\n                    \"dimensions\": f\"{img.width}x{img.height}\",\n                    \"dpi\": img.info.get(\"dpi\", (None, None)),\n                    \"size\": cls.format_file_size(filepath.stat().st_size),\n                    \"created\": cls.get_creation_date(filepath),\n                }\n        except Exception as e:\n            logging.error(f\"Image processing failed for {filepath}: {str(e)}\")\n            return None\n\n    @classmethod\n    def process_video(cls, filepath: Path) -> Optional[Dict]:\n        try:\n            if filepath.suffix.lower() == \".webm\":\n                # Use mutagen.File for .webm files\n                video = File(filepath)\n                duration = video.info.length\n            else:\n                # Use MP4 for other video formats\n                video = MP4(filepath)\n                duration = video.info.length\n\n            return {\n                \"type\": \"video\",\n                \"path\": str(filepath),\n                \"duration\": cls.format_duration(duration),\n                \"size\": cls.format_file_size(filepath.stat().st_size),\n                \"created\": cls.get_creation_date(filepath),\n            }\n        except Exception as e:\n            logging.error(f\"Video processing failed for {filepath}: {str(e)}\")\n            return None\n\n\nclass ScriptAnalyzer:\n    \"\"\"Handles script analysis using OpenAI.\"\"\"\n\n    @retry(\n        stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10)\n    )\n    def analyze_scripts_batch(self, scripts: List[Dict]) -> List[Dict]:\n        \"\"\"Analyze multiple scripts in a single API request.\"\"\"\n        if not openai:\n            return [{\"error\": \"OpenAI client not initialized\"}] * len(scripts)\n\n        try:\n            messages = [\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze this script:\\n{script['content'][:15000]}\\n\\nReturn categories and a title suggestion.\",\n                }\n                for script in scripts\n            ]\n\n            response = openai.chat.completions.create(model=\"gpt-4\", messages=messages)\n            return [\n                self._parse_response(choice.message.content, script[\"path\"])\n                for choice, script in zip(response.choices, scripts)\n            ]\n        except Exception as e:\n            logging.error(f\"AI analysis failed: {str(e)}\")\n            return [{\"error\": str(e)}] * len(scripts)\n\n    def _parse_response(self, response: str, filepath: Path) -> Dict:\n        # Add your custom response parsing logic here\n        return {\n            \"path\": str(filepath),\n            \"name\": filepath.name,\n            \"categories\": \"Uncategorized\",\n            \"title\": \"Untitled\",\n            \"analysis\": response,\n        }\n\n\ndef process_directory(\n    root_dir: Path, processor: MediaProcessor, file_type: str\n) -> List[Dict]:\n    \"\"\"Process all files in directory with appropriate handlers.\"\"\"\n    results = []\n    for item in root_dir.rglob(\"*\"):\n        if should_exclude(item):\n            continue\n\n        if item.is_file() and item.suffix.lower() in FILE_TYPES[file_type]:\n            handler = {\n                \"audio\": processor.process_audio,\n                \"image\": processor.process_image,\n                \"video\": processor.process_video,\n            }.get(file_type)\n\n            if handler:\n                result = handler(item)\n                if result:\n                    results.append(result)\n    return results\n\n\ndef write_results(results: List[Dict], output_path: Path):\n    \"\"\"Write processed results to CSV.\"\"\"\n    if not results:\n        logging.warning(\"No results to write\")\n        return\n\n    fieldnames = list(results[0].keys())\n    try:\n        with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n            writer = csv.DictWriter(f, fieldnames=fieldnames)\n            writer.writeheader()\n            writer.writerows(results)\n        logging.info(f\"Successfully wrote {len(results)} records to {output_path}\")\n    except Exception as e:\n        logging.error(f\"Failed to write CSV: {str(e)}\")\n\n\ndef main():\n    # Initialize processors\n    media_processor = MediaProcessor()\n    script_analyzer = ScriptAnalyzer()\n\n    # Prompt for directory\n    directory = prompt_for_directory()\n\n    # Process media files\n    for file_type in [\"audio\", \"image\", \"video\"]:\n        results = process_directory(directory, media_processor, file_type)\n        if results:\n            output_path = CONFIG_DIR / f\"{file_type}_analysis.csv\"\n            write_results(results, output_path)\n\n    # Process scripts\n    script_results = []\n    scripts_to_analyze = []\n    for script_path in directory.rglob(\"*.py\"):\n        if should_exclude(script_path):\n            continue\n\n        with safe_file_access(script_path) as f:\n            if f:\n                scripts_to_analyze.append({\"path\": script_path, \"content\": f.read()})\n\n    # Batch analyze scripts\n    if scripts_to_analyze:\n        script_results = script_analyzer.analyze_scripts_batch(scripts_to_analyze)\n        output_path = CONFIG_DIR / \"script_analysis.csv\"\n        write_results(script_results, output_path)\n\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n        logging.info(\"Operation cancelled by user\")\n    except Exception as e:\n        logging.error(f\"Critical failure: {str(e)}\", exc_info=True)\n"
        }
    ]
}